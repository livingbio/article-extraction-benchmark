{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import requests\n",
    "import json\n",
    "import html2text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. load ground truth\n",
    "2. use ground truth key to find html\n",
    "3. parse and filter content if needed\n",
    "4. store to json file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## clean readability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "with open(\"./ureka-output/readability.json\", \"r\") as in_file:\n",
    "    re = json.load(in_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "len(re)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "for key, v in re.items():\n",
    "    print(key)\n",
    "    re[key]['articleBody'] = filter_content(re[key]['articleBody']) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0113a10ki0ebyhk6eanowjafwuk4xs44cyjlrcmav59u7fbkaevlxewir04yzbxh\n",
      "15vo9dmc29newfu0pyhhejp7g9j3iilp7wipmp17wednp4y5aprhqx41xtognoo9\n",
      "2n6zn8x3b1l9n4sz0fnunilora7fo2lnu56rh4gg4e2j8n3qxrn9s7oz4i0ynegh\n",
      "40ganvwqtz9tqpz87k4tyfyy0wt8fjzrsbjtg4g5cxe2zc21u9gzws9cgjo88kkv\n",
      "541eq8jsm47djn9ue5cqvwn8quxonvm09r3aqah71vxg5a4ho3cx1cldbqjruaxe\n",
      "5q08666x0tyrabfmuvznx5kvx1rnvesblyyex15uscnkjtd3gjfwh0u1xnz26pij\n",
      "5txbsg1flqkdfmt1jyvivdpg1t4gax54mxy67edh6v7fz3kicnq5yygxbq0m2aap\n",
      "6iewwb0yx498k6hj1eb3cnnl6rcc9w3l78vrf8xaewdal2xucv6ocwaxumljub1a\n",
      "6il0x8lcbo2zf79vqqs9t2wpjm4mwt810agx4vfundjyko3q85zcgahkxbs2gej6\n",
      "6v351komzy5r3o9xn3r7jx57t6z0w1hh5139ydoszffspgkf7xj86h5svtqzd9f6\n",
      "6zet72js0zrtyni8ejhlf9om8zvztefy9sckp4oqr85yw12m0rauycwe4qr5ttam\n",
      "75n1a31iih563l93po4f6laeh6t15skjotwcrvyew0lt4rl61nm8chuqpq4f1kou\n",
      "850pnd468xzc3vpqqk9ffpbe8gpjwnuzyd9adnx0y0qza30ymo26x9afg08rr43u\n",
      "8jlkzakbu22y67jxll5oidwecdimierpjrn2tb9cftmizlavjl5ud8b37shqljde\n",
      "94jdmleruzjpvcdmjywau27n8ghh40leijm0pjkl48by2r4423m4oocmei4a02ro\n",
      "9bx9443n687yvhp2stu0dthrnrecny2zpjdjpk1hxq8y1xupuzxweqzaq0jgbsrn\n",
      "9npsqi7s7rx7pxo46wjpuhjyzily7ni5lz1g8law819u9664x83hxj7as5osvluy\n",
      "9oyksu0w3z3n8w1fobqhor63ugwfui96xuypzha4wj437k88n0vp48qqwv4dspdn\n",
      "9u43ceehx85cathyow4h52v242t43e0or1kwqtcm4erx37xjql4ido67wddng4v0\n",
      "9z5drefbqh9u14cwkhu0xo5b3d932l8mlpuwbo7y2ph3uuskhbxo2c8q0myz6vqn\n",
      "achd9jrqt30f9axcmhj7m5kuwj4yt83vmdefqbgs2cv05idpe8ip01i8oadku2e9\n",
      "ae11ju2h6mcy3d2nwmngk3jas8afd4tbo0qw76wojt5bw92dd2sx1a66yiebr3t0\n",
      "aleyqifaele9tfqnjkq8rvta1nch9cgkmr0yiqtjdrbdy77lh6973gpzp5uwcef9\n",
      "b6p33yn27oezu5y8lm5gavzhiezue2nazv6c4qth3c26zfkc4nwcrdekjckqqfnf\n",
      "beeg37won78ogzy7q7zzbq2js8l7oxsxoh4fjgbd3cuqpz1vdcgjnco2q45sto9f\n",
      "dhauznrhxuarlmd91apogib1yy9sc4h8ao47u80pihp6gbxi12i384h5z1a7myen\n",
      "egw3u28jhoacy96yxtrrn3b763xqktbg8hbkjir6z3ou23mv1gv4qikxi04azg49\n",
      "ezq3wrkpmsi0nc16lzsx1n0vn8e446gm7c8i4idw0d8k5lat1wblpen400iqcybf\n",
      "faf51bra21qlf7ncvl7w3izjqrm3zf4btzvskmiddph8pyrocvc8imtgm019r1mu\n",
      "fe1d1s3m7r144zkyn5wjn0rp2yjhv62u43y9wjxoi6t07t2y5jl2g643hfew4k2k\n",
      "gah0vo88ueccmt32h6m72j7h7hsf5jdmjdx9h5juzq88gepa0vdgszwq5l0shrq6\n",
      "gbj0mvz99mg81sh0ewpwsg0rvz93w7dn3x3x4cjn8xp3ztauzh8zew2nrbh85l0w\n",
      "h6kbg2yhvxvplveb4mibg8f1325rf9i2lcbzqeisyqjsmkrf85th4xrx2mhyd37e\n",
      "hp0thpcqb7vu5yb5foho9n6s9mjjs5jnga9m49v3um6iycihvtgz420ex3rriwqf\n",
      "ht0687gmwnubygwkrqfgyevdsim0v7opxg4fluytnzlcsoxy933q92lgy9ci6blp\n",
      "hw2k9lhi4ux31kp3izh8tguo4hgk74b88b30xftpc1z86h12cgonzbd5i38t7qcb\n",
      "ift3cwkpatudslri5e0gezivvptmlmyh1hi4iq3noxane1x852fpxnrs6k7nwxvd\n",
      "j75u4pc6axqb27cxamwbpqo8cnfumaldr5u19w73uvo5vqde7gcq9kfk4yjckkqh\n",
      "j8qjgy6zpch05fzmaafzcwp0ie7kvo0hvbgk5equfcia9lsai9lph1216udmzlep\n",
      "jfhxi5c8q2ykgt6zech9lbds1qu4zfmwhfhw7w5igvk2bf9p2o75uxbxhtnq9fth\n",
      "jrviluh6o9pm1msph8ash7p6uvuur16wcaai33nwf18yeedsrvbekogq4vuz5obz\n",
      "kkhala17de8xh094smabi3k19weicutoyud1kjomr670tozd0q94rcgxgc08ojrj\n",
      "kksrmdvd1tmmrr2gyqo5rip9fv9e6a2gtrfr5xddu8yofe0jtgpy9p8bvz7vmsq8\n",
      "ksuqf14vam7l8jhn4ccp8rjcmqv9w0cw6qwmdpsxgao1dxia722ovapuemxv33v4\n",
      "kzsqiukssd311hja7oukkpwb8jrxhtgkv66xr8c16vn86z0p8n5uex1ybw4b1izh\n",
      "l5zdgk0dzvva0wdlzefqu1timra43six1bsloy328nq9966qogkwkmp6c044r1qe\n",
      "lpxrt946xg8it5kzazohqigc2rz6al7xtag6m9dafjc5zofmlc2mnrcgvdop9imc\n",
      "luohnam1r9bj69p74lakxfhjpb6lx4xg1t506a633h6yb94au6oe4fz1ptrw43ei\n",
      "m7s5y2r7v2mrlfrwkeahnkxx9qw9nou5bz6chzpqiw3xzk07e0dki01mlqs78muc\n",
      "mgzytdu9xwer69nlzzouy9a58v4u5tnzxns9qs50m10pbeomqi9hnqke5p3cdraj\n",
      "mnke4i3gr9eycn3osdlgp28px99m1nckd2q5xkwom19re02koqwfwg6b49fhoiv2\n",
      "mpomyahr28l5qafp7pftz3pd882d21wa800268rd9odb6mkbddzrr8bzkb8wxti3\n",
      "mr2haxyzcrtp218sr8xug24grkiw9z6v81ebsv0lg65b1hn3pmavh92ukz587dlv\n",
      "nxn4eapgvqquigm4xzn27ngnte2emgypxjr8yo5alrxffgs2xgpdxpleh4q4qhmm\n",
      "o11qug09lvi8x3hmn596bfgsq44o4kf78x8fk13tokodhmx2timrejo8ffkzsu30\n",
      "o3f16swwkxpy01jpdtblv9mee9im5xz3k19u30dfph47qs8h8vfv6a8n4i3cqo3b\n",
      "o9uv3rc9bczjn2140ypctlq3fbgtl48jwv9w1ew2m95cob04ntox4cj9653iiwtb\n",
      "ocxt0ku36iu4kwasdm8y4h82han38o2sjgsompq88zmf0sefk5j0jd3zi9vx2vrr\n",
      "ospur0hq87m57djuzt4uppk1scrk0lxy5rimmuw88kpsk7olko8mmfavknphvgs0\n",
      "pd067bmt6lyrhkhr5yc50499lrq08uevpvzezt5xln4jkg3a3rnhq6p6moqc7ib5\n",
      "q3qpar6xy91ajopyqfwpgkejn4w1gl5p3b4h3adqu3yueczid0praj5o4yzh32ob\n",
      "q50ba75cz2vfop9qu82681nfym8a2z2xzx1lno45f8s018r2m14og2rnewx4wc1t\n",
      "qk5pw05vwz6nxfzyhv5qw6uxdnva6duhz7k9jjy8yv24auqckkcboy41qwzxeugl\n",
      "qxdoz5k94wxmz340wgpdbbdhsjxff4x26o90zzaxdeg6cermsf33kp4575dc88c8\n",
      "rjeccmon4hkyv99tacj9s0wwr3hu218a4q2ps0kbnigr9occnmv8vd33lxzhoemi\n",
      "tzn6vp7kp1o864odyj9upc0dgmhunkincmsix3rf39o7c1tebnj57rzosaj3akp7\n",
      "u2ep6k3nciw3976ttj5ykn5o0i9m0tyr9taciwn9mhfcvnnzu4mwcvznkfmqbatt\n",
      "u4pm5dsp2cu2rme7xcptwnbf82xf4xeclmj5mdmcz9bdzfltthc51zcu1yv114n9\n",
      "uig627129sjj2us5s91onl8da6skdyxp0i0ocx73ahhivfd8rcv5l8yb4g5v1y16\n",
      "wraykxssq8pd8u9q2gok72rppq77xirtdqcbnwqjisfbila5rtujdzf7lg9i230d\n",
      "x6kh4166jqoxugzr2p37nyo4d0mgq9p41m78v5o8c6d29i2svuklj6vjshwoeans\n",
      "xbnl0ndpot5klmrvu91uccrj8j8azjbkesy8zqu1rspges8mojz86nf6st9i37ar\n",
      "xkqtjyhzcbkuh5lanw98az35ggvdoxfrp3arr3wuw5l7pcbiigju54b14638d3qw\n",
      "xq48mkdh5vpgq79txlwlmkyv5jbvb514kgqapn3onnlgs5ioghjpjwgysxh6jgfj\n",
      "ynfvm5dxr3i71a922f5l901tjyb7isv5q0ys5akv0hho5o4qnft0k946rpiosias\n",
      "ypbopmk6wtj0yk957iowcit79r141zjaybjdfliv5zlfazek3to0jxex4how95sr\n",
      "yzc312beskz9rv9ukwi4my8pm75u90x7e4vzdjb87zh68dhbhfcpysxzqw80pn15\n",
      "zm3iw8gwcwx04v5xf7z8hzrgxovp8olnwvmpfbw5psbni02gi0mtqbkinbriqnk9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "for key, v in re.items():\n",
    "    re[key]['articleBody'] = filter_urltext(re[key]['articleBody']) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "with open('./ureka-output/readability.json', 'w') as out_file:\n",
    "    json.dump(re, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# for filter readability's content of [text](url)\n",
    "def filter_urltext(text):\n",
    "    t = text\n",
    "    while t.find('](') != -1:\n",
    "        start = t.find('](')\n",
    "        back_stack = -1\n",
    "        back = 0\n",
    "        while back_stack != 0:\n",
    "            back -= 1\n",
    "            if t[start + back] == '[':\n",
    "                back_stack += 1\n",
    "            elif t[start + back] == ']':\n",
    "                back_stack -= 1\n",
    "            \n",
    "        \n",
    "        url = start + 1\n",
    "        step = 0\n",
    "        stack = 1\n",
    "        while stack != 0:\n",
    "            step += 1\n",
    "            if t[url + step] == '(':\n",
    "                stack += 1\n",
    "            elif t[url + step] == ')':\n",
    "                stack -= 1\n",
    "            \n",
    "        t = t[:start + back] + t[start + back + 1 : start] + t[url + step + 1 :] \n",
    "    return t"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# gparser"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "with open('./ureka-output/gparser.json', 'r') as in_file:\n",
    "    gt = json.load(in_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "# crawl by our parser\n",
    "def gparser(url):\n",
    "    # api = \"https://genv-parsed-al23s7k26q-de.a.run.app/parse-article?url=\"\n",
    "    api = \"https://gparsed-admin.gliaoffice.com/parsed/api/parse?url=\"\n",
    "    json_file = requests.get(api + url).json()\n",
    "    return html2text.html2text(json_file['parsed_content']['content'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# crawl by our parser\n",
    "def gparserM(url):\n",
    "    api = \"https://genv-parsed-al23s7k26q-de.a.run.app/parse-article?name=MachineParserV2&url=\"\n",
    "    json_file = requests.get(api + url).json()\n",
    "    return html2text.html2text(json_file['parsed_content']['content'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# filter image text e.g. ![](https://thehill.com/sites/default/files/styles/thumb_100/public/noemkristi_030217gn.jpg?itok=UMIpgu97)\n",
    "def filter_content(text):\n",
    "    t = text\n",
    "    while t.find('![') != -1:\n",
    "        start = t.find('![')\n",
    "        step = 1\n",
    "        stack = 0\n",
    "        while t[start + step: start + step + 2] != '](':\n",
    "            step = step + 1\n",
    "        step = step + 1\n",
    "        stack = stack + 1 \n",
    "\n",
    "        while stack != 0:\n",
    "            step += 1\n",
    "            if t[start + step] == '(':\n",
    "                stack = stack + 1\n",
    "            elif t[start + step] == ')':\n",
    "                stack = stack - 1 \n",
    "        end = start + step\n",
    "        t = t[:start] + t[end+1:]\n",
    "    return t"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "with open('./new-html/6z83qve5cuuqwgwrq8mbf632apkei3x7cstfz4z16y1jpt7muprcagodlagpbxpf.html', 'r') as f:\n",
    "    html = f.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for key in gt.keys():\n",
    "    try:\n",
    "        # our parser's result need to filter\n",
    "        gt[key]['articleBody'] = filter_urltext(filter_content(gparserM(gt[key]['url'])))\n",
    "    except:\n",
    "        print(key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3izzk985i1bhsf4n8o6xw8ksd8jxjyh4awm7fivylvldm6sgzef5a7aykr1rpp39\n",
      "4mq9odxag2a8im8mxzeekvt8ozeb4s73i804qsvk4u3ff1gg223b5lnkx9c87dos\n",
      "6z83qve5cuuqwgwrq8mbf632apkei3x7cstfz4z16y1jpt7muprcagodlagpbxpf\n",
      "7hc6vgzocot60heurtw4d0oevm929bi9lv9yqejtakhhsmqi4d0j1i673hi2aqqi\n",
      "8mdohfog5gt4z5cjud8zhoq1fbiwbc7l6py8iq2qbejuj6jcechi4txkyf3bez9j\n",
      "d0nzwqdvesweiw7qeq6iycdq1ifvqpdhpw68b1zwy5v11hu9w7wn5s7ufkufre6u\n",
      "dhpur8x95e0s0vjh6j720b5oo5iu0o7w0iv30skoq5sdl3omxum0uio7i4s6bc1l\n",
      "e42rxpk5jb99ax0s7v1pa0k7k1finp00w4rv2hzor1b0kntsy1x6osprhlr6ww3y\n",
      "eb62ac8425e5573947ecde962d14433d18e5725cc4a8c908fe22f678e96a65a1\n",
      "es6u7b1cckyxajo1j7siw6v4a0bfb3gt19b1ym6uk8hrx4eqkp6mc8pbj3ewdkpp\n",
      "fooa6lkmaviiz1hi2hj0gvmp2okzc7y74u6g6miu3xtoqxk9a0aaa2mqj315bnjr\n",
      "g21cu3e8vj8urdroxihlyekwptvvtauqgghhm4yemvn64xhiwyjsbbvxt3yosr4e\n",
      "gtx25qwy6d9gpvof7l5nul794scuvvtq3rupy44xfqv70muavjiv1xf3zvs8fyij\n",
      "kqjy3st4yy74v742ckvakc0j838hva09j2he83i11otno0lbjez6eoqfwem03sfs\n",
      "n92vfi1lukzb1owxtc3495jzh9mgy5umnl5aa39wii9uljn18536a24wnf3rit0u\n",
      "oafesfig3gldiv0cf62c48si1xohcbr3mym26cqhnprtjhqkb80xhd52ikj32wvn\n",
      "tui4fneowdea7xfoafifkiqgy5p2nucvvxwgzgkrxytbiydmdg91e6yr2j0ztl9r\n",
      "u18fbxm4n3tmq1gkn7v9cyh330365dc7pb14hxq7bwtuccqkb24uvdh8q85oxexa\n",
      "xuir1mp1gi0yo0d46ppmyyf31mmneqnn3v6rsno69ohxf25kbrlyqs8g36bf0z4l\n",
      "yoq4amsswhdvzut9ob19va6npmucozl6qe1dhovhbyksn4zczfw88zlwkrb8s55n\n",
      "zsgzmxoaoznmgq6nn8ua3j8lpgdwmbn6k2iznl7g9l7742q5r5883wxh3qvqsvh1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "gt[key]['articleBody'] = d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "url = \"https://ireneslife.com/blog/post/tai-food-3\"\n",
    "d = gparser(url)\n",
    "filter_content(d)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'【三重】試賣期間的泰小吃店，銅板價格的道地泰國味，不會每道菜吃起來味道都一樣\\n\\n按Line加入好友\\n\\n\\n\\n三重好吃的泰式餐廳、泰式小吃超級多，近期又發現一家「泰小吃店」，\\n\\n大大的「泰」字招牌很顯眼，騎車經過時不免被吸引了目光；\\n\\n目前尚在試賣中，搶先來嚐嚐鮮。\\n\\n\\n\\n\\n\\n店內空間不大，大多是兩人座，不適合人數太多來用餐，\\n\\n牆壁上的裝飾品很有泰國味。\\n\\n\\n\\n\\n\\n沒有菜單，只有牆壁黑板上寫的六種品項，餐點種類不多，但都是蠻基本款的。\\n\\n聽到老闆用泰文跟廚房的人點餐，看來掌廚的應該是泰國人，煮出來的料理應該很道地吧。\\n\\n\\n\\n店家招待一人一小杯的泰式奶茶，猜想應該是之後會推出的品項吧，\\n\\n還蠻香濃的，泰式奶茶因為加了煉乳大多偏甜，\\n\\n但至少不要像螞蟻的食物都可以接受，泰小吃店的濃淡剛剛好。\\n\\n\\n\\n餐點可以跟店家告知不要加辣，打拋豬肉飯(NT.80)要給小朋友吃所以沒加辣，\\n\\n泰小吃店的打拋豬沒辣也很好吃。\\n\\n\\n\\n飯上還附一顆半熟蛋，最愛半熟蛋的口感。\\n\\n\\n\\n玉米筍、洋蔥、四季豆、紅蘿蔔、肉末都切碎碎的，拌著飯吃剛剛好，\\n\\n泰小吃店的打拋豬調味跟泰式餐廳的不太一樣，沒有太重的香料味跟調味，\\n\\n味道吃來甜甜的，口味不重，很順口，蠻合我們的口味。\\n\\n\\n\\n海鮮媽媽麵(重)(NT.90)有分輕跟重兩種口味，店家比較推薦重口味，\\n\\n於是就選了重口味的海鮮媽媽麵，另外辣度選擇了小辣試試看。\\n\\n\\n\\n熱騰騰上桌的海鮮媽媽麵光看就很好吃，透抽、去殼的鮮蝦都很新鮮，\\n\\n媽媽麵沒有炒到過軟爛，仍飽有咬勁，小辣的辣度就很明顯，對我來說有些過辣，\\n\\n但融入大火快炒的鍋氣，又香又辣還是讓人欲罷不能。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n整盤看起來超白的泰炒粉條(NT.90)，似乎少了點視覺上的饗宴，\\n\\n以大量豆芽菜拌炒粉條，都是白色透明的元素，除了鮮蝦是紅色外。\\n\\n\\n\\n不辣的泰炒粉條吃起來有著豆腐般的輕爽，黏稠滑順，\\n\\n豆芽菜的脆口搭配著柔軟的粉條，更好互補，口感層次上更豐富，\\n\\n味道上很不一樣的泰炒粉條，但也讓我們當天三道料理的風味截然不同，\\n\\n不是每一款吃起來都是一樣的味道。\\n\\n\\n\\n\\n\\n每份餐點都額外附一碗白蘿蔔湯，看似普通的菜頭湯，喝起來好甘甜，\\n\\n白蘿蔔也煮到軟透入味，免費的附湯居然讓人驚艷！\\n\\n只是吃泰式小吃搭配台式菜頭湯感覺好像有點奇怪(笑)。\\n\\n\\n\\n\\n\\n迷你小巧的泰小吃店，作業的人手不多，遇到人多時可能要包容一下，\\n\\n當天吃到的都不差，最喜歡打拋豬跟媽媽麵，希望之後有更多的餐點品項推出。\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "url = \"https://ireneslife.com/blog/post/tai-food-3\"\n",
    "d = gparserM(url)\n",
    "filter_content(d)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n\\n三重好吃的泰式餐廳、泰式小吃超級多，近期又發現一家「泰小吃店」，\\n\\n大大的「泰」字招牌很顯眼，騎車經過時不免被吸引了目光；\\n\\n目前尚在試賣中，搶先來嚐嚐鮮。\\n\\n\\n\\n\\n\\n店內空間不大，大多是兩人座，不適合人數太多來用餐，\\n\\n牆壁上的裝飾品很有泰國味。\\n\\n\\n\\n\\n\\n沒有菜單，只有牆壁黑板上寫的六種品項，餐點種類不多，但都是蠻基本款的。\\n\\n聽到老闆用泰文跟廚房的人點餐，看來掌廚的應該是泰國人，煮出來的料理應該很道地吧。\\n\\n\\n\\n店家招待一人一小杯的泰式奶茶，猜想應該是之後會推出的品項吧，\\n\\n還蠻香濃的，泰式奶茶因為加了煉乳大多偏甜，\\n\\n但至少不要像螞蟻的食物都可以接受，泰小吃店的濃淡剛剛好。\\n\\n\\n\\n餐點可以跟店家告知不要加辣，打拋豬肉飯(NT.80)要給小朋友吃所以沒加辣，\\n\\n泰小吃店的打拋豬沒辣也很好吃。\\n\\n\\n\\n飯上還附一顆半熟蛋，最愛半熟蛋的口感。\\n\\n\\n\\n玉米筍、洋蔥、四季豆、紅蘿蔔、肉末都切碎碎的，拌著飯吃剛剛好，\\n\\n泰小吃店的打拋豬調味跟泰式餐廳的不太一樣，沒有太重的香料味跟調味，\\n\\n味道吃來甜甜的，口味不重，很順口，蠻合我們的口味。\\n\\n\\n\\n海鮮媽媽麵(重)(NT.90)有分輕跟重兩種口味，店家比較推薦重口味，\\n\\n於是就選了重口味的海鮮媽媽麵，另外辣度選擇了小辣試試看。\\n\\n\\n\\n熱騰騰上桌的海鮮媽媽麵光看就很好吃，透抽、去殼的鮮蝦都很新鮮，\\n\\n媽媽麵沒有炒到過軟爛，仍飽有咬勁，小辣的辣度就很明顯，對我來說有些過辣，\\n\\n但融入大火快炒的鍋氣，又香又辣還是讓人欲罷不能。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n整盤看起來超白的泰炒粉條(NT.90)，似乎少了點視覺上的饗宴，\\n\\n以大量豆芽菜拌炒粉條，都是白色透明的元素，除了鮮蝦是紅色外。\\n\\n\\n\\n不辣的泰炒粉條吃起來有著豆腐般的輕爽，黏稠滑順，\\n\\n豆芽菜的脆口搭配著柔軟的粉條，更好互補，口感層次上更豐富，\\n\\n味道上很不一樣的泰炒粉條，但也讓我們當天三道料理的風味截然不同，\\n\\n不是每一款吃起來都是一樣的味道。\\n\\n\\n\\n\\n\\n每份餐點都額外附一碗白蘿蔔湯，看似普通的菜頭湯，喝起來好甘甜，\\n\\n白蘿蔔也煮到軟透入味，免費的附湯居然讓人驚艷！\\n\\n只是吃泰式小吃搭配台式菜頭湯感覺好像有點奇怪(笑)。\\n\\n\\n\\n\\n\\n迷你小巧的泰小吃店，作業的人手不多，遇到人多時可能要包容一下，\\n\\n當天吃到的都不差，最喜歡打拋豬跟媽媽麵，希望之後有更多的餐點品項推出。\\n\\n**泰小吃店**\\n\\n地址：新北市三重區信義西街140號\\n\\n試賣營業時間：11:00~14:00;17:00~21:00\\n\\n**更多平價泰式料理：**\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for key, v in gt.items():\n",
    "    try:\n",
    "        gt[key]['articleBody'] = filter_content(gparser(gt[key]['url']))\n",
    "    except:\n",
    "        print(key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fvqnj6ev1kzrz7wfa63tsueckit34jwda107sh90hd2p8q30zsf2cfi6u2hud302\n",
      "h7n8td7t090dag40imly1zidb3d4vkv9ycozllc77siyfh9ntlvlx99641vpql07\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open('./test2-output/gparser.json', 'r') as f:\n",
    "    gp = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for key in gt.keys():\n",
    "    if key != \"\":\n",
    "        gt[key]['articleBody'] = filter_urltext(filter_content(gt[key]['articleBody']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "gt[\"fvqnj6ev1kzrz7wfa63tsueckit34jwda107sh90hd2p8q30zsf2cfi6u2hud302\"]['articleBody'] = filter_content(d)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "with open('./sorted_f_output/gparser_machinev2.json', 'w') as out_file:\n",
    "    json.dump(gt, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "failed_g = [\"897xoz2hcjal44bdsu70xzpprasuj0drew8tavgaqtm3skvfjp4opne02rv0ufi4\",\n",
    "           \"c50845a7158af12ee75acea301a3ea0dad1e848d6b9dbdb43ba7f2d825b2528b\",\n",
    "           \"cw3o1yuu51cp95glyh0qfhhdsiauvh4lncnc957tfuvj90seoh99nfdoupmm8k2l\",\n",
    "           \"ffjv0vgvy7e1nuh7t59qtnaz7r76ksf2znangkij08o54qjlxhnjbfnkjw31chjs\",\n",
    "           \"g0d4heng35y5vo5atgvk1zgtmsh57u817ombinrrsqhozz5p8wfju0pdn5i4363g\",\n",
    "           \"l04dj4q0xvg0tw0r36lhh9giu6kn2wjut3y166z9dqyyfaedq53wordkt4c8os16\",\n",
    "           \"op6asw6cqo3vlw875oqhahd9w1wg6kbrk38fqvddsiabwi2loho9etqxrcsy4id5\"\n",
    "           ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "for k in failed_g:\n",
    "    del gt[k]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "with open('./test2-output/gparser.json', 'w') as out_file:\n",
    "    json.dump(gp, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# goose3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from goose3 import Goose"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def goose(html):\n",
    "    g = Goose()\n",
    "    article = g.extract(raw_html=html)\n",
    "    return article.cleaned_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "with open('./ureka_dataset.json', 'r') as f:\n",
    "    gt = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "\n",
    "with open(f'./ureka-html/0113a10ki0ebyhk6eanowjafwuk4xs44cyjlrcmav59u7fbkaevlxewir04yzbxh.html', 'r') as f:\n",
    "        html = f.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "goose(html)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "for key in gt.keys():\n",
    "    \n",
    "    with open(f'./ureka-html/{key}.html', 'r') as f:\n",
    "        html = f.read()\n",
    "    gt[key]['articleBody'] = \"\"\n",
    "    try:\n",
    "        gt[key]['articleBody'] = goose(html)\n",
    "    except:\n",
    "        print(f'failed: {key}')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "with open('./ureka-output/goose3.json', 'w') as out_file:\n",
    "    json.dump(gt, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# News_please"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from newsplease import NewsPlease"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def news_please(html):\n",
    "    article = NewsPlease.from_html(html, url=None)\n",
    "    return article.maintext"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "with open('./ureka_dataset.json', 'r') as f:\n",
    "    gt = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for key in gt.keys():\n",
    "    \n",
    "    with open(f'./ureka-html/{key}.html', 'r') as f:\n",
    "        html = f.read()\n",
    "    gt[key]['articleBody'] = \"\"\n",
    "    try:\n",
    "        gt[key]['articleBody'] = news_please(html)\n",
    "    except:\n",
    "        print(f'failed: {key}')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "fail_np = [\"g0d4heng35y5vo5atgvk1zgtmsh57u817ombinrrsqhozz5p8wfju0pdn5i4363g\", \n",
    "             \"gifoi8czpcytfvi0m1xhmezba9n9pflh7h9ibcrvuibq5dbz85h192e8t7xl4r4p\",\n",
    "            \"npf7492tfhu4gshrkwsd3pu705huxhqrckesxwoeeybs0lyjwez9z3t91y4qsm8s\",\n",
    "            \"op6asw6cqo3vlw875oqhahd9w1wg6kbrk38fqvddsiabwi2loho9etqxrcsy4id5\",\n",
    "            \"ur24hbi7lnwlhsaei1fysaujpbqm7dcx34akgykgmorxu76ogsxrw4h58vgyyor7\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for key in gt.keys():\n",
    "    if gt[key]['articleBody'] == None:\n",
    "        gt[key]['articleBody'] = \"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "for k in fail_np:\n",
    "    del gt[k]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "with open('./ureka-output/news_please.json', 'w') as out_file:\n",
    "    json.dump(gt, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# readability-lxml"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 會將連結爬下來"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from readability import Document"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def readability(html):\n",
    "    doc = Document(html)\n",
    "    text = html2text.html2text(doc.summary(html_partial=True))\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "with open('./ureka_dataset.json', 'r') as f:\n",
    "    gt = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for key in gt.keys():\n",
    "    \n",
    "    with open(f'./ureka-html/{key}.html', 'r') as f:\n",
    "        html = f.read()\n",
    "    gt[key]['articleBody'] = \"\"\n",
    "    try:\n",
    "        gt[key]['articleBody'] = readability(html)\n",
    "    except:\n",
    "        print(f'failed: {key}')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "fail_read = [\"897xoz2hcjal44bdsu70xzpprasuj0drew8tavgaqtm3skvfjp4opne02rv0ufi4\",\n",
    "\"kuyuaqbveg39d0wkjjgcbausls15vkfjen0f2f71wlfu24r9fdeyaj0bhqo2dojb\",\n",
    "\"r9736qhnpst24anxa3bxc3m8le2o9i8uoyb8jpyrn4bg2z41dz1v2kxcww1s69bw\",\n",
    "\"ur24hbi7lnwlhsaei1fysaujpbqm7dcx34akgykgmorxu76ogsxrw4h58vgyyor7\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "for k in fail_read:\n",
    "    del gt[k]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "with open('./ureka-output/readability.json', 'w') as out_file:\n",
    "    json.dump(gt, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# trafilatura"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import trafilatura as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def trafilatura(html):\n",
    "    return tf.extract(html, include_comments=False)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "with open('./ureka_dataset.json', 'r') as f:\n",
    "    gt = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "for key in gt.keys():\n",
    "    \n",
    "    with open(f'./ureka-html/{key}.html', 'r') as f:\n",
    "        html = f.read()\n",
    "    gt[key]['articleBody'] = \"\"\n",
    "    try:\n",
    "        gt[key]['articleBody'] = trafilatura(html)\n",
    "    except:\n",
    "        print(f'failed: {key}')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "with open('./ureka-output/trafilatura.json', 'w') as out_file:\n",
    "    json.dump(gt, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dragnet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from dragnet import extract_content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def dragnet(html):\n",
    "    content = extract_content(html, encoding='utf8')\n",
    "    return content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "with open('./ureka_dataset.json', 'r') as f:\n",
    "    gt = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for key in gt.keys():\n",
    "    \n",
    "    with open(f'./ureka-html/{key}.html', 'r') as f:\n",
    "        html = f.read()\n",
    "    gt[key]['articleBody'] = \"\"\n",
    "    try:\n",
    "        gt[key]['articleBody'] = dragnet(html)\n",
    "    except:\n",
    "        print(f'failed: {key}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/kevin/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator FeatureUnion from version 0.19.1 when using version 0.20.4. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kevin/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator ExtraTreeClassifier from version 0.19.1 when using version 0.20.4. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kevin/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator ExtraTreesClassifier from version 0.19.1 when using version 0.20.4. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "with open(\"./ureka-output/dragnet.json\", 'w') as f:\n",
    "    json.dump(gt, f, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "with open('./sorted_f_output/dragnet.json', 'w') as out_file:\n",
    "    json.dump(gt, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# newspaper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from newspaper import Article"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# crawl by newspaper\n",
    "def newspaper(url, html):\n",
    "    article = Article(url)\n",
    "    article.set_html(html)\n",
    "    article.parse()\n",
    "    return article.text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "with open('./ureka_dataset.json', 'r') as f:\n",
    "    gt = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for key in gt.keys():\n",
    "    with open(f'./ureka-html/{key}.html', 'r') as f:\n",
    "        html = f.read()\n",
    "    \n",
    "    url = gt[key]['url']\n",
    "    gt[key]['articleBody'] = \"\"\n",
    "    try:\n",
    "        gt[key]['articleBody'] = newspaper(url, html)\n",
    "    except:\n",
    "        print(f'failed: {key}')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "with open(\"./ureka-output/newspaper.json\", 'w') as f:\n",
    "    json.dump(gt, f, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for key, v in gt.items():\n",
    "        try:\n",
    "            gt[key]['articleBody'] = newspaper(gt[key]['url'])\n",
    "        except:\n",
    "            print(key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "042bb7b5fedab6eac7db576522b89b93904c237d344bcbe14a6a5ab7f7335856\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from /Users/kevin/opt/anaconda3/lib/python3.7/site-packages/jieba/dict.txt ...\n",
      "Loading model from cache /var/folders/xr/kcttlwdj7rj1fympt_1dl7d80000gn/T/jieba.cache\n",
      "Loading model cost 1.2423999309539795 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c13b9c0e04fb28d445d22e92bff6ab7f7800a429930677c28c4dad89f3269869\n",
      "efql3krlp3p03avgquvjym2re00ukelmpn1cdcasvvlc9ap1pm3rgq83skqk77c3\n",
      "f344ca5fb36e130f4344235fa22726f3367e09c211c120f21d9ae92effe902db\n",
      "f8ff621a0b9b7646cc0d57d37416feabba2bf78ef5dd0bfc5b080f9f97bbe584\n",
      "g0d4heng35y5vo5atgvk1zgtmsh57u817ombinrrsqhozz5p8wfju0pdn5i4363g\n",
      "gifoi8czpcytfvi0m1xhmezba9n9pflh7h9ibcrvuibq5dbz85h192e8t7xl4r4p\n",
      "ig58r4vwc2i2afwl83u7ub9d8a3ox2hykrdah8oyo344wj7j690on0e18s4xhu2f\n",
      "th76oyeq31o02aa65u4kxfb2ddil60ytwq21ac1lzkalg3tkgaaqem4wn1prk4jj\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "with open('./sorted_f_output/newspaper.json', 'w') as out_file:\n",
    "    json.dump(gt, out_file, sort_keys=True, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}